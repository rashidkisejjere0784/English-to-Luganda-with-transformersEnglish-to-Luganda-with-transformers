{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGXNs89MWx2KSUqZuRm+uO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rashidkisejjere0784/English-to-luganda-with-transformers/blob/main/Luganda_to_English_with_transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9pLgOFQgiZX2"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import TextVectorization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "XA1bv7W9kda6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('Luganda.csv', encoding = \"ISO-8859-1\")\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gaDDQ1ILkgfE",
        "outputId": "a8acf800-25ee-4272-fd47-16575fa0c481"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             English  \\\n",
              "0  All refugees were requested to register with t...   \n",
              "1     They called for a refugees' meeting yesterday.   \n",
              "2  Refugees had misunderstandings between   thems...   \n",
              "3  We were urged to welcome refugees into our com...   \n",
              "4  More development is achieved when we work toge...   \n",
              "\n",
              "                                             Luganda  Unnamed: 2  Unnamed: 3  \n",
              "0  Abanoonyiboobubudamu bonna baasabiddwa beewand...         NaN         NaN  \n",
              "1  Baayise olukungaana lw'abanoonyiboobubudamu eg...         NaN         NaN  \n",
              "2  Abanoonyiboobubudamu b'abadde n'obutakkaanya w...         NaN         NaN  \n",
              "3  Twakubirizibwa okwaniriza abanoonyiboobubudamu...         NaN         NaN  \n",
              "4  Bwe tukolera awamu enkulaakulana enyingi efuni...         NaN         NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-317bddf9-0468-42cb-bab0-37337e2d7c82\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Luganda</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>All refugees were requested to register with t...</td>\n",
              "      <td>Abanoonyiboobubudamu bonna baasabiddwa beewand...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>They called for a refugees' meeting yesterday.</td>\n",
              "      <td>Baayise olukungaana lw'abanoonyiboobubudamu eg...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Refugees had misunderstandings between   thems...</td>\n",
              "      <td>Abanoonyiboobubudamu b'abadde n'obutakkaanya w...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>We were urged to welcome refugees into our com...</td>\n",
              "      <td>Twakubirizibwa okwaniriza abanoonyiboobubudamu...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>More development is achieved when we work toge...</td>\n",
              "      <td>Bwe tukolera awamu enkulaakulana enyingi efuni...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-317bddf9-0468-42cb-bab0-37337e2d7c82')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-317bddf9-0468-42cb-bab0-37337e2d7c82 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-317bddf9-0468-42cb-bab0-37337e2d7c82');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[[\"English\", \"Luganda\"]]\n",
        "data = data.dropna()"
      ],
      "metadata": {
        "id": "iL3boHtokgar"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.iloc[0]['English']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DmwnFOuUmFih",
        "outputId": "47966481-b96b-4812-fa80-a05c4500cbea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'All refugees were requested to register with the chairman.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_pairs = []\n",
        "for lug, eng in zip(data['Luganda'], data['English']):\n",
        "    lug = \"[start]\" + lug + \"[end]\"\n",
        "    text_pairs.append((eng, lug))"
      ],
      "metadata": {
        "id": "K90cxJx2kgWj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_pairs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyBpgMBZkgSd",
        "outputId": "36f7b552-e276-482b-8134-b9518e755ce1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('All refugees were requested to register with the chairman.',\n",
              "  '[start]Abanoonyiboobubudamu bonna baasabiddwa beewandiise ewa ssentebe.[end]'),\n",
              " (\"They called for a refugees' meeting yesterday.\",\n",
              "  \"[start]Baayise olukungaana lw'abanoonyiboobubudamu eggulo.[end]\"),\n",
              " ('Refugees had misunderstandings between   themselves.',\n",
              "  \"[start]Abanoonyiboobubudamu b'abadde n'obutakkaanya wakati waabwe.[end]\"),\n",
              " ('We were urged to welcome refugees into our communities.',\n",
              "  '[start]Twakubirizibwa okwaniriza abanoonyiboobubudamu mu bitundu byaffe.[end]'),\n",
              " ('More development is achieved when we work together.',\n",
              "  '[start]Bwe tukolera awamu enkulaakulana enyingi efunibwa.[end]'),\n",
              " ('The border districts are insecure.',\n",
              "  '[start]Disitulikiti eziriraanye ensalo si ntebenkevu.[end]'),\n",
              " ('Refugees have started practicing farming so as to earn a living.',\n",
              "  '[start]Abanoonyiboobubudamu batandise okulima okusobola okwebeezaawo.[end]'),\n",
              " ('It is illegal to own a gun.',\n",
              "  \"[start]Kimenya mateeka okubeera n'emmundu.[end]\"),\n",
              " ('He is very disrespectful to his parents.',\n",
              "  '[start]Awa nnyo bazadde be kitiibwa.[end]'),\n",
              " ('He takes a lot of alcohol.', '[start]Omusajja anywa nnyo omwenge.[end]')]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(text_pairs)\n",
        "num_val_samples = int(0.05 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples :]\n",
        "\n",
        "print(f\"{len(text_pairs)} total pairs\")\n",
        "print(f\"{len(train_pairs)} training pairs\")\n",
        "print(f\"{len(val_pairs)} validation pairs\")\n",
        "print(f\"{len(test_pairs)} test pairs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSfH9cTOkgOx",
        "outputId": "1b244b58-d0d6-480e-968e-0686bf6b9d95"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15021 total pairs\n",
            "13519 training pairs\n",
            "751 validation pairs\n",
            "751 test pairs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(\" \".join(data['Luganda']).split()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-84nUhRcnegE",
        "outputId": "2d7a6412-2a76-4691-8475-33630929308f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24693"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strip_chars = string.punctuation + \"¿\"\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
        "\n",
        "\n",
        "eng_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size, output_mode=\"int\", output_sequence_length=sequence_length,\n",
        ")\n",
        "lug_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "train_eng_texts = [pair[0] for pair in train_pairs]\n",
        "train_lug_texts = [pair[1] for pair in train_pairs]\n",
        "eng_vectorization.adapt(train_eng_texts)\n",
        "lug_vectorization.adapt(train_lug_texts)"
      ],
      "metadata": {
        "id": "CmXe-Im5kgLV"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_dataset(eng, lug):\n",
        "    eng = eng_vectorization(eng)\n",
        "    lug = lug_vectorization(lug)\n",
        "    return ({\"encoder_inputs\": eng, \"decoder_inputs\": lug[:, :-1],}, lug[:, 1:])\n",
        "\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, lug_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    lug_texts = list(lug_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, lug_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ],
      "metadata": {
        "id": "aA9deMN-phs6"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kHwRPqKphoz",
        "outputId": "72f253e9-aac1-4f86-d1a3-dbcae6e78cbe"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (64, 20)\n",
            "inputs[\"decoder_inputs\"].shape: (64, 20)\n",
            "targets.shape: (64, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n",
        "        attention_output = self.attention(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
        "        )\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)"
      ],
      "metadata": {
        "id": "EXtYhRxWphl9"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)"
      ],
      "metadata": {
        "id": "YzhAkakUphin"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
        "        )\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
        "            axis=0,\n",
        "        )\n",
        "        return tf.tile(mask, mult)"
      ],
      "metadata": {
        "id": "8qY4DGzdphfr"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 256\n",
        "latent_dim = 2048\n",
        "num_heads = 8\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "\n",
        "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "transformer = keras.Model(\n",
        "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        ")"
      ],
      "metadata": {
        "id": "_pUAMqjfqNwK"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1\n",
        "\n",
        "transformer.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPypqGC_qNu7",
        "outputId": "ef30851d-966d-424b-e53e-f445057a8399"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " positional_embedding_2 (Positi  (None, None, 256)   3845120     ['encoder_inputs[0][0]']         \n",
            " onalEmbedding)                                                                                   \n",
            "                                                                                                  \n",
            " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " transformer_encoder_1 (Transfo  (None, None, 256)   3155456     ['positional_embedding_2[0][0]'] \n",
            " rmerEncoder)                                                                                     \n",
            "                                                                                                  \n",
            " model_3 (Functional)           (None, None, 15000)  12959640    ['decoder_inputs[0][0]',         \n",
            "                                                                  'transformer_encoder_1[0][0]']  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 19,960,216\n",
            "Trainable params: 19,960,216\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.compile(\n",
        "    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "bziFVFPpqNmG"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.fit(train_ds, epochs=epochs, validation_data=val_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FP3p58CMqNi3",
        "outputId": "8d68d84b-97fd-4237-92f1-625957ab6846"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "212/212 [==============================] - 22s 69ms/step - loss: 2.5021 - accuracy: 0.1597 - val_loss: 2.1576 - val_accuracy: 0.2043\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa1257af040>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = transformer.fit(train_ds, epochs=50, validation_data=val_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLPfNeo2qNf7",
        "outputId": "4f6f3f08-e613-4eea-8994-481bf2f83d5a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "212/212 [==============================] - 14s 65ms/step - loss: 2.3823 - accuracy: 0.1818 - val_loss: 2.0462 - val_accuracy: 0.2124\n",
            "Epoch 2/50\n",
            "212/212 [==============================] - 14s 66ms/step - loss: 2.3329 - accuracy: 0.1934 - val_loss: 2.0435 - val_accuracy: 0.2515\n",
            "Epoch 3/50\n",
            "212/212 [==============================] - 14s 65ms/step - loss: 2.3047 - accuracy: 0.1996 - val_loss: 2.0762 - val_accuracy: 0.2392\n",
            "Epoch 4/50\n",
            "212/212 [==============================] - 14s 65ms/step - loss: 2.2897 - accuracy: 0.2045 - val_loss: 2.0090 - val_accuracy: 0.2643\n",
            "Epoch 5/50\n",
            "212/212 [==============================] - 14s 64ms/step - loss: 2.2509 - accuracy: 0.2105 - val_loss: 1.9882 - val_accuracy: 0.2780\n",
            "Epoch 6/50\n",
            "212/212 [==============================] - 14s 64ms/step - loss: 2.2222 - accuracy: 0.2174 - val_loss: 1.9952 - val_accuracy: 0.2909\n",
            "Epoch 7/50\n",
            "212/212 [==============================] - 14s 65ms/step - loss: 2.1915 - accuracy: 0.2251 - val_loss: 2.0488 - val_accuracy: 0.2867\n",
            "Epoch 8/50\n",
            "212/212 [==============================] - 14s 65ms/step - loss: 2.1709 - accuracy: 0.2280 - val_loss: 1.9575 - val_accuracy: 0.2873\n",
            "Epoch 9/50\n",
            "212/212 [==============================] - 14s 65ms/step - loss: 2.1583 - accuracy: 0.2301 - val_loss: 1.9686 - val_accuracy: 0.2937\n",
            "Epoch 10/50\n",
            "212/212 [==============================] - 14s 64ms/step - loss: 2.1442 - accuracy: 0.2341 - val_loss: 1.9993 - val_accuracy: 0.2882\n",
            "Epoch 11/50\n",
            "212/212 [==============================] - 14s 64ms/step - loss: 2.1316 - accuracy: 0.2367 - val_loss: 1.9850 - val_accuracy: 0.2975\n",
            "Epoch 12/50\n",
            "212/212 [==============================] - 14s 65ms/step - loss: 2.1191 - accuracy: 0.2406 - val_loss: 1.9343 - val_accuracy: 0.2950\n",
            "Epoch 13/50\n",
            "212/212 [==============================] - 14s 65ms/step - loss: 2.1126 - accuracy: 0.2431 - val_loss: 1.9432 - val_accuracy: 0.2890\n",
            "Epoch 14/50\n",
            "212/212 [==============================] - 14s 64ms/step - loss: 2.1028 - accuracy: 0.2454 - val_loss: 1.9441 - val_accuracy: 0.2950\n",
            "Epoch 15/50\n",
            "212/212 [==============================] - 14s 64ms/step - loss: 2.0902 - accuracy: 0.2483 - val_loss: 2.0246 - val_accuracy: 0.2963\n",
            "Epoch 16/50\n",
            "212/212 [==============================] - 14s 65ms/step - loss: 2.0819 - accuracy: 0.2494 - val_loss: 1.9544 - val_accuracy: 0.2959\n",
            "Epoch 17/50\n",
            "212/212 [==============================] - 14s 64ms/step - loss: 2.0737 - accuracy: 0.2527 - val_loss: 1.9910 - val_accuracy: 0.3041\n",
            "Epoch 18/50\n",
            "212/212 [==============================] - 14s 65ms/step - loss: 2.0671 - accuracy: 0.2536 - val_loss: 1.9701 - val_accuracy: 0.3001\n",
            "Epoch 19/50\n",
            "212/212 [==============================] - 14s 64ms/step - loss: 2.0570 - accuracy: 0.2569 - val_loss: 1.9267 - val_accuracy: 0.3014\n",
            "Epoch 20/50\n",
            "212/212 [==============================] - 14s 64ms/step - loss: 2.0492 - accuracy: 0.2572 - val_loss: 1.9607 - val_accuracy: 0.3031\n",
            "Epoch 21/50\n",
            "212/212 [==============================] - 14s 64ms/step - loss: 2.0378 - accuracy: 0.2585 - val_loss: 1.9712 - val_accuracy: 0.3054\n",
            "Epoch 22/50\n",
            "212/212 [==============================] - 13s 64ms/step - loss: 2.0317 - accuracy: 0.2607 - val_loss: 1.9542 - val_accuracy: 0.2990\n",
            "Epoch 23/50\n",
            "212/212 [==============================] - 14s 64ms/step - loss: 2.0269 - accuracy: 0.2625 - val_loss: 1.9616 - val_accuracy: 0.3016\n",
            "Epoch 24/50\n",
            "212/212 [==============================] - 14s 64ms/step - loss: 2.0183 - accuracy: 0.2650 - val_loss: 1.9900 - val_accuracy: 0.2943\n",
            "Epoch 25/50\n",
            "212/212 [==============================] - 14s 64ms/step - loss: 2.0122 - accuracy: 0.2673 - val_loss: 1.9624 - val_accuracy: 0.3014\n",
            "Epoch 26/50\n",
            "212/212 [==============================] - 14s 64ms/step - loss: 1.9999 - accuracy: 0.2686 - val_loss: 1.9669 - val_accuracy: 0.3035\n",
            "Epoch 27/50\n",
            "212/212 [==============================] - 14s 64ms/step - loss: 1.9918 - accuracy: 0.2721 - val_loss: 1.9888 - val_accuracy: 0.2905\n",
            "Epoch 28/50\n",
            "212/212 [==============================] - 14s 65ms/step - loss: 1.9871 - accuracy: 0.2717 - val_loss: 1.9976 - val_accuracy: 0.2916\n",
            "Epoch 29/50\n",
            "212/212 [==============================] - 14s 64ms/step - loss: 1.9799 - accuracy: 0.2749 - val_loss: 1.9779 - val_accuracy: 0.2976\n",
            "Epoch 30/50\n",
            "212/212 [==============================] - 14s 65ms/step - loss: 1.9781 - accuracy: 0.2770 - val_loss: 2.0105 - val_accuracy: 0.2920\n",
            "Epoch 31/50\n",
            "212/212 [==============================] - 14s 64ms/step - loss: 1.9745 - accuracy: 0.2778 - val_loss: 1.9664 - val_accuracy: 0.2967\n",
            "Epoch 32/50\n",
            "212/212 [==============================] - 14s 66ms/step - loss: 1.9655 - accuracy: 0.2790 - val_loss: 2.0294 - val_accuracy: 0.2890\n",
            "Epoch 33/50\n",
            "212/212 [==============================] - 14s 66ms/step - loss: 1.9619 - accuracy: 0.2795 - val_loss: 1.9750 - val_accuracy: 0.2886\n",
            "Epoch 34/50\n",
            "212/212 [==============================] - 14s 65ms/step - loss: 1.9515 - accuracy: 0.2815 - val_loss: 1.9726 - val_accuracy: 0.2950\n",
            "Epoch 35/50\n",
            "212/212 [==============================] - 14s 66ms/step - loss: 1.9400 - accuracy: 0.2849 - val_loss: 2.0160 - val_accuracy: 0.2875\n",
            "Epoch 36/50\n",
            "212/212 [==============================] - 14s 64ms/step - loss: 1.9355 - accuracy: 0.2859 - val_loss: 2.0464 - val_accuracy: 0.2773\n",
            "Epoch 37/50\n",
            "212/212 [==============================] - 14s 66ms/step - loss: 1.9265 - accuracy: 0.2884 - val_loss: 2.0095 - val_accuracy: 0.2850\n",
            "Epoch 38/50\n",
            "212/212 [==============================] - 14s 64ms/step - loss: 1.9190 - accuracy: 0.2899 - val_loss: 2.0576 - val_accuracy: 0.2720\n",
            "Epoch 39/50\n",
            "212/212 [==============================] - 14s 65ms/step - loss: 1.9217 - accuracy: 0.2918 - val_loss: 2.0112 - val_accuracy: 0.2829\n",
            "Epoch 40/50\n",
            "212/212 [==============================] - 14s 64ms/step - loss: 1.9134 - accuracy: 0.2920 - val_loss: 1.9947 - val_accuracy: 0.2907\n",
            "Epoch 41/50\n",
            "212/212 [==============================] - 14s 65ms/step - loss: 1.9102 - accuracy: 0.2944 - val_loss: 1.9787 - val_accuracy: 0.2867\n",
            "Epoch 42/50\n",
            "212/212 [==============================] - 13s 63ms/step - loss: 1.9018 - accuracy: 0.2968 - val_loss: 2.0223 - val_accuracy: 0.2846\n",
            "Epoch 43/50\n",
            "212/212 [==============================] - 14s 64ms/step - loss: 1.8955 - accuracy: 0.2994 - val_loss: 2.0254 - val_accuracy: 0.2737\n",
            "Epoch 44/50\n",
            "212/212 [==============================] - 14s 64ms/step - loss: 1.8892 - accuracy: 0.3010 - val_loss: 2.0089 - val_accuracy: 0.2782\n",
            "Epoch 45/50\n",
            "212/212 [==============================] - 14s 64ms/step - loss: 1.8853 - accuracy: 0.3039 - val_loss: 2.0199 - val_accuracy: 0.2771\n",
            "Epoch 46/50\n",
            "212/212 [==============================] - 14s 64ms/step - loss: 1.8804 - accuracy: 0.3058 - val_loss: 2.0039 - val_accuracy: 0.2769\n",
            "Epoch 47/50\n",
            "212/212 [==============================] - 14s 64ms/step - loss: 1.8795 - accuracy: 0.3058 - val_loss: 2.0039 - val_accuracy: 0.2765\n",
            "Epoch 48/50\n",
            "212/212 [==============================] - 14s 64ms/step - loss: 1.8780 - accuracy: 0.3085 - val_loss: 1.9538 - val_accuracy: 0.2961\n",
            "Epoch 49/50\n",
            "212/212 [==============================] - 14s 64ms/step - loss: 1.8779 - accuracy: 0.3105 - val_loss: 1.9520 - val_accuracy: 0.2984\n",
            "Epoch 50/50\n",
            "212/212 [==============================] - 14s 64ms/step - loss: 1.8807 - accuracy: 0.3115 - val_loss: 1.9498 - val_accuracy: 0.2988\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lug_vocab = lug_vectorization.get_vocabulary()\n",
        "lug_index_lookup = dict(zip(range(len(lug_vocab)), lug_vocab))\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = eng_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = lug_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = lug_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZDdSXeoFqNco"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rJwfNtV7w0mD",
        "outputId": "0375ac57-60bf-418f-d30a-d108e43da7b9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'District leaders have discouraged gender based violence.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translated"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "H5k6parnqNZW",
        "outputId": "ab5cfac5-4969-4614-f7ff-613cd5ee98bd"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[start] ba disitulikiti [UNK] ku [UNK] ku [UNK] ku [UNK]  [UNK]  [UNK]    [UNK]  [UNK] '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "for _ in range(30):\n",
        "    input_sentence = random.choice(test_eng_texts)\n",
        "    translated = decode_sequence(input_sentence)\n",
        "    print(input_sentence)\n",
        "    print(translated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlUCGJrkqNWD",
        "outputId": "ee64347d-41cf-45f1-e8bb-b52333ff2f56"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "People should work towards achieving rural development.\n",
            "[start] balina okwenyigira mu kufuna okwenyigira ku mirimu [UNK]  [UNK] [UNK]      [UNK]  [UNK] \n",
            "Who is responsible for providing students with food at school?\n",
            "[start] [UNK] abantu [UNK] ku [UNK] ku ssomero[end]  ssomero[end] zaabwe[end] ssomero[end]      ssomero[end]  bulijjo[end] \n",
            "The business community informed the council to involve people in the planning process.\n",
            "[start] [UNK] ku ngeri [UNK] [UNK] nga [UNK] [UNK]  [UNK] [UNK]      [UNK]  [UNK] \n",
            "What causes well  s to dry up?\n",
            "[start] otya [UNK] oluvannyuma kyalo ki[end]  mateeka[end] [UNK] lunaku[end] ki[end] lunaku[end]      mateeka[end]  ki[end] \n",
            "The ban should be lifted after the laboratory test results.\n",
            "[start] alina [UNK] [UNK] [UNK] mu [UNK]  [UNK] [UNK] [UNK] [UNK]      [UNK]  [UNK] \n",
            "The government has failed to ensure proper water supply within the area.\n",
            "[start] [UNK] abantu balina [UNK] mu kitundu[end]  kitundu[end] kitundu[end] kitundu[end]       kitundu[end]  [UNK] \n",
            "The president has information to give to the nation publically.\n",
            "[start] bulijjo [UNK] ku [UNK] mu [UNK]  [UNK] [UNK] [UNK] ki[end]      [UNK]  [UNK] \n",
            "Parents should help their kids with homework.\n",
            "[start] balina okuwa okufuna baabwe [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK]      [UNK]  [UNK] \n",
            "You must buy a cultural marriage certificate for a successful introduction.\n",
            "[start] [UNK] [UNK] kirungi [UNK] ku [UNK] mu [UNK]  [UNK] [UNK]  [UNK]    [UNK]  [UNK] [UNK]\n",
            "Politics can lead to hatred among various contestants.\n",
            "[start] [UNK] ku ttaka mu biseera mu bantu[end]  [UNK] [UNK] [UNK]  [UNK]    [UNK]  [UNK] [UNK]\n",
            "Politicians are making all sorts of promises to the people.\n",
            "[start] [UNK] ku [UNK] ku [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]      [UNK]  [UNK] \n",
            "One of the pedestrians gave the casualties first aid at the scene.\n",
            "[start] [UNK] mu [UNK] ku [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK]  [UNK]    [UNK]  [UNK] \n",
            "Some leadership systems are oppressive to people.\n",
            "[start] ebimu [UNK] nga [UNK] ku bizinensi[end]  [UNK] [UNK] [UNK] [UNK]      [UNK]  [UNK] \n",
            "The doctor has taken blood samples to test for malaria.\n",
            "[start] [UNK] [UNK] omusujja ebimu omusujja gwensiri[end]  gwensiri[end] otya gwensiri[end] lunaku[end]      katonda[end]  [UNK] \n",
            "It is the headteacher's role to keep students safe while at school.\n",
            "[start] [UNK] balina balina [UNK] mu [UNK] ku ngeri [UNK] mu [UNK]  zaabwe[end]    ssomero[end]  zaabwe[end] \n",
            "My brother is very hardworking.\n",
            "[start] gwange [UNK] nti [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]      [UNK]  [UNK] \n",
            "Let us hurry because the court is about to begin.\n",
            "[start] [UNK] mu kkooti mu kkooti[end]  [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK]    [UNK]  [UNK] kkanisa[end]\n",
            "The president has come out to criticize criminals carrying out assassinations.\n",
            "[start] [UNK] [UNK] [UNK] [UNK] [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK]      [UNK]  [UNK] \n",
            "The health team is doing all it can to manage corona patients.\n",
            "[start] [UNK] ku [UNK] ku gavumenti akawuka ka ssenyiga ssenyiga ssenyiga ssenyiga ssenyiga ssomero[end]    ssomero[end]  kya \n",
            "Leaders lack information about the whereabouts of the refugees.\n",
            "[start] tebalina ttaka ku [UNK]  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]      [UNK]  [UNK] \n",
            "Who is responsible for providing students with food at school?\n",
            "[start] [UNK] abantu [UNK] ku [UNK] ku ssomero[end]  ssomero[end] zaabwe[end] ssomero[end]      ssomero[end]  bulijjo[end] \n",
            "Uganda's agricultural sector has received attention from foreign investors.\n",
            "[start] mu uganda [UNK] ku [UNK] ku [UNK]  [UNK] [UNK] [UNK]  [UNK]    [UNK]  [UNK] [UNK]\n",
            "The government wants to come up with laws against tobacco growing.\n",
            "[start] [UNK] abantu abantu ku ngeri [UNK] ku [UNK]  [UNK] [UNK]  [UNK]    [UNK]  [UNK] [UNK]\n",
            "coronavirus  test updates show a rising number of cases in border districts of Uganda\n",
            "[start] [UNK] mu kolona akawuka ka gavumenti [UNK] mu gavumenti [UNK] mu uganda [UNK] mu gavumenti[end]  gavumenti[end]  [UNK] \n",
            "The lawbreakers have been taken to the courts of law\n",
            "[start] [UNK] [UNK] [UNK] mu ddwaliro[end]  [UNK] [UNK] katonda[end] [UNK] kkooti[end]      katonda[end]  [UNK] \n",
            "The district in Northern Uganda was chosen to implement the project.\n",
            "[start] mu uganda [UNK] mu masomero [UNK] mu pulojekiti[end]  [UNK] [UNK]  pulojekiti[end]    pulojekiti[end]  [UNK] \n",
            "Our toilets are very dirty.\n",
            "[start] [UNK] [UNK] [UNK]  [UNK] nnyo[end] katonda[end] [UNK]  ki[end]       katonda[end]  ki[end] \n",
            "Christian families yieldgood future citizens of the nation.\n",
            "[start] [UNK] mu [UNK] mu bulamu [UNK] mu [UNK]  [UNK] [UNK]  [UNK]    [UNK]  [UNK] [UNK]\n",
            "In order to follow the curriculum principal individual-study material for learners have been synchronized.\n",
            "[start] bulijjo [UNK] [UNK] [UNK] [UNK] [UNK] ku ngeri [UNK] ku poliisi[end]      poliisi[end]  [UNK] \n",
            "Football funs sometimes are not happy when the club sells its players.\n",
            "[start] ebimu bameka bameka [UNK]  nga [UNK] [UNK] [UNK] [UNK] [UNK]      [UNK]  [UNK] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZS5LUqmIphdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zT6O3BZZkgHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HK3-tiefkgDy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}